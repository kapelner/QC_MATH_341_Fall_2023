\documentclass[12pt]{article}

\include{preamble}

\newtoggle{professormode}
\toggletrue{professormode} %STUDENTS: DELETE or COMMENT this line



\title{MATH 341/641 Fall \the\year{} Homework \#7}

\author{Professor Adam Kapelner} %STUDENTS: write your name here

\iftoggle{professormode}{
\date{(not officially due) \\ \vspace{0.5cm} \small (this document last updated \today ~at \currenttime)}
}

\renewcommand{\abstractname}{Instructions and Philosophy}

\begin{document}
\maketitle

\iftoggle{professormode}{
\begin{abstract}
The path to success in this class is to do many problems. Unlike other courses, exclusively doing reading(s) will not help. Coming to lecture is akin to watching workout videos; thinking about and solving problems on your own is the actual ``working out.''  Feel free to \qu{work out} with others; \textbf{I want you to work on this in groups.}

Reading is still \textit{required}. For this homework set, review MATH 340 concepts: mixture distributions, poisson, gamma, extended negative binomial, normal, inverse gamma, students T.

The problems below are color coded: \ingreen{green} problems are considered \textit{easy} and marked \qu{[easy]}; \inorange{yellow} problems are considered \textit{intermediate} and marked \qu{[harder]}, \inred{red} problems are considered \textit{difficult} and marked \qu{[difficult]} and \inpurple{purple} problems are extra credit. The \textit{easy} problems are intended to be ``giveaways'' if you went to class. Do as much as you can of the others; I expect you to at least attempt the \textit{difficult} problems. \qu{[MA]} are for those registered for 621 and extra credit otherwise.

This homework is worth 100 points but the point distribution will not be determined until after the due date. See syllabus for the policy on late homework.

Up to 5 points are given as a bonus if the homework is typed using \LaTeX. Links to instaling \LaTeX~and program for compiling \LaTeX~is found on the syllabus. You are encouraged to use \url{overleaf.com}. If you are handing in homework this way, read the comments in the code; there are two lines to comment out and you should replace my name with yours and write your section. The easiest way to use overleaf is to copy the raw text from hwxx.tex and preamble.tex into two new overleaf tex files with the same name. If you are asked to make drawings, you can take a picture of your handwritten drawing and insert them as figures or leave space using the \qu{$\backslash$vspace} command and draw them in after printing or attach them stapled.

The document is available with spaces for you to write your answers. If not using \LaTeX, print this document and write in your answers. I do not accept homeworks which are \textit{not} on this printout. Keep this first page printed for your records.

\end{abstract}

\thispagestyle{empty}
\vspace{1cm}
NAME: \line(1,0){380}
\clearpage
}


\input{R_equations_table}


\problem{We will ask some basic problems on the Gamma-Poisson conjugate model.}

\begin{enumerate}

\intermediatesubproblem{Prove that the Poisson likelihood for $n$ observations, i.e. $\Xoneton ;\theta \iid \poisson{\theta}$, with a gamma prior yields a gamma posterior and find its parameters.}\spc{8}

\easysubproblem{Now that you see the posterior, provide a pseudodata interpretation for both hyperparameters.}\spc{6}

\intermediatesubproblem{Find the Bayesian point estimates as function of the data and prior's hyperparameters (i.e. $\thetahathatmmse$, $\thetahathatmmae$ and $\thetahathatmap$).}\spc{6}

%\intermediatesubproblem{If $\Xoneton ;\theta \iid \poisson{\theta}$, find $\thetahathatmle$.}\spc{6}

\intermediatesubproblem{Demonstrate that $\thetahathatmmse$ is a shrinkage estimator and find $\rho$.}\spc{4}

%\intermediatesubproblem{Demonstrate that $\prob{\theta} \propto 1$ is improper.}\spc{2}

%\easysubproblem{[MA] Demonstrate that $\prob{\theta} \propto 1$ can be created by using an improper Gamma distribution (i.e. a Gamma distribution with parameters that are not technically in its parameter space and thereby does not admit a distribution function).}\spc{5}

\intermediatesubproblem{Write the Laplace, Haldane and Jeffrey's conjugate priors below. They are all improper.}\spc{3}

%\easysubproblem{What is the equivalent of the Haldane prior in the Binomial likelihood model for the Poisson likelihood model? Use an interpretation of pseudocounts to explain.}\spc{4}

%\hardsubproblem{If $\prob{\theta} = \gammanot{\alpha}{\beta}$ where $\alpha \in \naturals$, prove that prior predictive distribution is $\prob{X} = \negbin{r}{p} := \binom{x + r - 1}{r - 1}(1-p)^{x}p^r$ where $p = \beta / (\beta + 1)$ and $r = \alpha$. This is a little bit different than that posterior predictive distribution derivation we did in class but mostly the same.}\spc{12}

%\intermediatesubproblem{If $\alpha \notin \naturals$, create an \qu{extended negative binomial} r.v. and find its PMF. You can copy from Wikipedia.}\spc{3}


%\intermediatesubproblem{Why is the extended negative binomial r.v. also known as the gamma-Poisson mixture distribution? Why is it also called the \qu{overdispersed Poisson}?}\spc{2}



\intermediatesubproblem{If you observe $0,3,2,4,2,6,1,0,5$, give a 90\% CR for $\theta$. Pick a principled objective (uninformative) prior.}\spc{5}

\intermediatesubproblem{Using the data and the prior from (f), test if $\theta < 2$.}\spc{2}

\hardsubproblem{Using the data and the prior from (f), find the probability the next observation will be a 7. Leave in exact form using Table 1's notation.}\spc{5}

%\easysubproblem{Use the R calculator (if you don't have it on your computer, go to \url{https://rdrr.io/snippets/}) to compute it to the nearest two significat digits.}\spc{1}

%\hardsubproblem{[MA] We talked about that the negative binomial is an \qu{overdispersed} Poisson. Show that this negative binomial converges to a Poisson as $n \rightarrow \infty$ by showing PMF convergence.}\spc{12}

\extracreditsubproblem{[MA] Find the joint posterior predictive distribution for $m$ future observations. I couldn't find the answer to this myself nor compute the integral.}\spc{20}
\end{enumerate}




\problem{We now discuss the theory of the normal-normal conjugate model. Assume the DGP: $\Xoneton~|~\theta,\sigsq \iid \normnot{\theta}{\sigsq}$ and $\sigsq$ known. \qu{$X$}, is the usual shorthand for all $\Xoneton$.}

\begin{enumerate}

%\easysubproblem{Show that the kernel of the normal distribution is, $\prob{X_1~|~\theta,~\sigsq} \propto k(X_1~|~\theta,~\sigsq) = e^{ax} e^{-bx^2}$ and solve for the values of $a$ and $b$ as functions of $\theta$ and $\sigsq$.}\spc{3}

\intermediatesubproblem{Assume $f(\theta\,|\,\sigsq) = \normnot{\mu_0}{\sigsq / n_0}$. Show that posterior distribution is normal and find its parameters.}\spc{6}


\easysubproblem{Provide pseudocount interpretations of $\mu_0$ and $n_0$.}\spc{1}

\easysubproblem{Find the Bayesian point estimates as function of the data and prior's hyperparameters (i.e. $\thetahathatmmse$, $\thetahathatmmae$ and $\thetahathatmap$).}\spc{1}


\intermediatesubproblem{Show that $\thetahatmmse$ is a shrinkage estimator and find $\rho$.}\spc{2}


\easysubproblem{What is the posterior distribution under Laplace's prior of indifference?}\spc{3}

\easysubproblem{Assuming $\sigsq = 1.3$, Laplace's prior and a dataset of $n=10$ with values 0.48  0.39  1.29  1.02  1.55 -0.22  0.01 -0.52 -1.50  0.71, provide a Bayesian point estimate.}\spc{1}

\easysubproblem{Assuming the prior, $\sigsq$ and the dataset from (f), provide a 95\% CR for $\theta$.}\spc{1}

\easysubproblem{Assuming the prior, $\sigsq$ and the dataset from (f), provide notation that calculates the $p$ value for a test of $H_a: \theta < 1$.}\spc{2}

%\intermediatesubproblem{Rederive Jeffrey's prior. Is it proper?}\spc{5}

%\intermediatesubproblem{Now let $\tau^2 := \sigsq / n_0$ which is a reparameterization from $\tau^2$ to $n_0$. Substitute this change into the posterior distribution from (b) to derive the posterior distribution under this reparemterization.}\spc{3}


\easysubproblem{Using the pseudocount interpretations of $\mu_0$ and $n_0$, what is Haldane's prior of ignorance? Is it proper?}\spc{1}


%\easysubproblem{If the prior is $\prob{\theta} = \normnot{\mu_0}{\sigsq / n_0}$, write the integral that will compute the posterior predictive distribution $\cprob{X_*}{X, \sigsq}$ when $n_*=1$.}\spc{20}

\hardsubproblem{Derive the posterior predictive distribution $f(X_*\,|\,X, \sigsq)$ when $n_*=1$. Try to do it yourself and if you get stuck, look in the notes.}\spc{20}

\end{enumerate}


\problem{We now discuss the theory of the normal-inverse-gamma conjugate model. Assume the DGP: $\Xoneton~|~\theta,\sigsq \iid \normnot{\theta}{\sigsq}$ and $\theta$ known. \qu{$X$}, is the usual shorthand for all $\Xoneton$.}

\begin{enumerate}

\easysubproblem{Assume the Laplace prior, $f(\sigsq\,|\,\theta) \propto 1$. Show that posterior  $f(\sigsq\,|\,X, \theta)$ is inverse gamma (and find the posterior parameters).}\spc{5}


%\easysubproblem{Plot a few PDF's of inverse gammas with different parameters to illustrate the different possible shapes.}\spc{9}

\easysubproblem{Show that posterior of $\sigsq~|~X,~\theta$ is inverse gamma (and find the posterior parameters) if $\prob{\sigsq} = \invgammanot{\overtwo{n_0}}{\overtwo{n_0 \sigsq_0}}$.}\spc{5}


\easysubproblem{What is the pseudodata interpretation of the hyperparameters $n_0$ and $\sigsq_0$?}\spc{1}

\easysubproblem{Based on the pseudodata interpretation of the hyperparameters $n_0$ and $\sigsq_0$, what would Haldane's prior be and why?}\spc{1}

\hardsubproblem{In the Laplace prior, what are the hyperparameters?}\spc{2}

\hardsubproblem{Why is the Laplace prior a bad idea to use in this modeling setting?}\spc{5}

\easysubproblem{Provide all three Bayesian point estimates for $\sigsq$ given $\theta$.}\spc{1}

\easysubproblem{Show that the $\thetahatmmse$ is a linear shrinkage estimator. Is it valid for every inverse gamma prior?}\spc{2}

\intermediatesubproblem{Show that the $\thetahathatmap$ is a linear shrinkage estimator (i.e. a linear combination of the MLE and the prior mode). Is it valid for every inverse gamma prior?}\spc{2}

\easysubproblem{What is the predictive distribution $f(X^*\,|\,X, \theta)$ if $n^*=1$ and $\theta \sim \invgammanot{\overtwo{n_0}}{\overtwo{n_0 \sigsq_0}}$?}\spc{1}


\intermediatesubproblem{Find a 95\% posterior predictive interval (PI) for the next observation.}\spc{3}

\end{enumerate}

\problem This question is about building models for the prices of cars sold at dealerships.

\begin{figure}[htp]
\centering
\includegraphics[width=2.7in]{accord.jpg}
\end{figure}

The 2016 Honda Accord sells at many different dealerships in New York City but sell it for more and some for less. We'll assume that the final negotiated price is distributed normally because it's most likely the sum of many different negotiation factors.

Our goal here is to determine the mean price at a certain car dealership in Astoria that people have been saying is \qu{too cheap} and if it's too cheap, Honda corporate may wish to investigate.

\begin{enumerate}



\intermediatesubproblem{Assume that each Accord's price at the Astoria dealership is normal and $\iid$ given the parameters. The nationwide variance for a Honda Accord selling price we're going to assume is $\sigsq = \$1000^2$. You and your colleague go down to the Astoria dealership undercover and ask to buy a Honda. After much negotiation, they will sell it to you for \$19,000 and they will sell it to your colleague for \$18,200 but they sense something suspicious so you hesitate to send another one of your guys down there to do another faux negotiation. Unfortunately, we're going to have to estimate the mean with just $x_1=19000$ and $x_2 = 18200$. What is your best guess of the mean price of Honda Accords sold here? Assume your prior from (a).}\spc{2}

\intermediatesubproblem{Based on this data, we wish to test if this dealership is selling Honda Accords below the manufacturer sugested retail price (MSRP) of \$22,205 --- if so, they would be subject to a fine. Calculate a $p$-value for this test below by using notation from Table~\ref{tab:eqs} but do not solve numerically.}\spc{4}

\hardsubproblem{What is the probability I get a really good deal --- that I can buy a car from these Astoria people for under \$17,000? Use the notation from Table~\ref{tab:eqs} but do not solve numerically.}\spc{3}



\end{enumerate}

\problem This question is about building a model to understand the accuracy of this beverage-filling machine pictured below:

\begin{figure}[htp]
\centering
\includegraphics[width=3.7in]{milk_filling.jpg}
\end{figure}

This machine fills 12oz plastic bottles. There is no doubt the mean amount of liquid filled per bottle is 12oz as been determined by the final weights of pallets of filled bottles. But we are uncertain about the variance. We decide to do an experiment and select $n = 21$ bottles at random and measure the amount of liquid in each bottle. Here are the measurements:

\begin{verbatim}
                   12.00 12.05 11.98 11.66 12.05 11.92 12.03
                   12.23 12.36 11.57 12.04 12.10 11.99 12.47
                   12.57 11.83 12.20 12.48 12.14 12.14 12.74
\end{verbatim}

Assume an $\iid$ normal model.

\begin{enumerate}
\easysubproblem{Find the MLE for $\sigsq$.}\spc{1}

\intermediatesubproblem{Under the Jeffrey's prior for $\sigsq$, find the posterior of $\sigsq$ by solving for the parameter values.}\spc{1}

\intermediatesubproblem{Write an expression for the 95\% left-sided credible region for $\sigsq$. This is a one sided CR which will give the upper bound for the machine's variance.}\spc{1}


\intermediatesubproblem{The bottles are actually 13.5oz. This means that you wish to test if $\sigsq > 0.352$ for if so, about 1/100,000 of the bottles will be overfull and that's the tolerance of the factory. Write an expression for the Bayesian p-value of this test.}\spc{2}


\intermediatesubproblem{Write an expression for the probability the next bottle has more than 13oz of liquid.}\spc{2}

%\intermediatesubproblem{Write an expression for the 95\% posterior predictive interval (PI) for the amount of liquid in the next bottle.}\spc{3}
\end{enumerate}


\problem{Now we will move to the Bayesian normal-normal model for estimating both the mean and variance and demonstrate similarities with the classical results.}

\begin{enumerate}

\easysubproblem{If $\Xoneton~|~\theta, \sigsq \iid \normnot{\theta}{\sigsq}$ and $X$ represents all $\Xoneton$. Find the kernel of the posterior if $f(\theta,~\sigsq) \propto \oneover{\sigsq}$. Use the substitution that we made in class $\sum_{i=1}^n (x_i - \theta)^2 = (n-1)s^2 + n(\xbar - \theta)^2$ where $s^2 := \oneover{n-1} \sum_{i=1}^n (x_i -\xbar)^2$. }\spc{8}


\easysubproblem{Using Bayes Rule, break up the posterior into two pieces as we did in class. How are those two pieces distributed?}\spc{2}

\hardsubproblem{Using Bayes Rule, partition the posterior into two differently than the previous question. How are those two pieces distributed?}\spc{2}

\intermediatesubproblem{Using your answer from (b), explain in English how you can create $S$ samples from the posterior distribution that look like $\braces{\bracks{\theta_1, \sigsq_1}, \bracks{\theta_2, \sigsq_2}, \ldots, \bracks{\theta_S, \sigsq_S}}$.}\spc{8}

\hardsubproblem{Using these samples, how would you estimate $\cexpe{\theta}{X}$ and $\cexpe{\sigsq}{X}$?}\spc{5}


\hardsubproblem{Using these samples, how would you estimate a 95\% CR for $\theta$?}\spc{6}

\hardsubproblem{Using these samples, how would you obtain a $p$-val for testing if $\sigsq > 1.364$?}\spc{6}

\hardsubproblem{[MA] Using these samples, how would you estimate $\corr{\theta~|~X}{~\sigsq~|~X}$ i.e. the correlation between the posterior distributions of the two parameters?}\spc{7}

%\easysubproblem{If $\Xoneton~|~\theta, \sigsq \iid \normnot{\theta}{\sigsq}$ and $\theta \sim \normnot{\mu_0}{\tausq}$ write the distribution of $\theta~|~X,\sigsq$. Hint: it's in the notes and it was HW6 6(d). Note this problem is independent of the other problems.}\spc{5}

%\easysubproblem{Find $\cprob{\theta}{X,~\sigsq}$ by using the full posterior kernel from (a) and then conditioning on $\sigsq$. You should get the same answer as we did before the midterm.}\spc{3}

%\easysubproblem{Find $\cprob{\sigsq}{X,~\theta}$ by using the full posterior kernel from (a)  and then conditioning on $\theta$. You should get the same answer as we did before the midterm.}\spc{4}

%\intermediatesubproblem{Show that $\cprob{\sigsq}{X}$ is an inverse gamma distribution and find its parameters.}\spc{4}

%\hardsubproblem{Show that $\cprob{\theta}{X}$ is a non-standard $T$ distribution and find its parameters. Assume the prior $\prob{\theta,~\sigsq} \propto \oneover{\sigsq}$. The answer is in the notes, but try to do it yourself.}\spc{15}


%\hardsubproblem{Show that $\cprob{\sigsq}{X}$ is an inverse gamma and find its parameters. Assume the prior $\prob{\theta,~\sigsq} \propto \oneover{\sigsq}$. The answer is in the notes, but try to do it yourself.}\spc{12}


%\intermediatesubproblem{How does this compare to 2(j)? Note that $X \sim \invgammanot{\alpha}{\beta}$ then $cX \sim \invgammanot{\alpha}{\frac{\beta}{c}}$.}\spc{2}


%\extracreditsubproblem{Prove what you wrote in the previous question: $\cprob{X^*}{X}$ is the non-standard $T$ distribution and find its parameters.}\spc{0}


\hardsubproblem{Explain how to sample from the posterior predictive distribution of for the next observation.}\spc{9}


\easysubproblem{How is $X^*\,|\,X$ distributed assuming the prior $f(\theta, \sigsq) \propto \oneover{\sigsq}$?}\spc{1}

\intermediatesubproblem{[MA] Now consider the informative conjugate prior of $\theta\,|\,\sigsq \sim \normnot{\mu_0}{\frac{\sigsq}{m}}$ and $\sigsq \sim \invgammanot{\overtwo{n_0}}{\overtwo{n_0 \sigsq_0}}$. Find the posterior and demonstrate it that the normal-inverse gamma is conjugate for the normal likelihood with both mean and variance unknown. This is what I did \emph{not} do in class.}\spc{13}

\end{enumerate}

\problem{We model the returns of S\&P 500 here.}

\begin{enumerate}
\easysubproblem{Below are the 16,428 daily returns (as a percentage) of the S\&P 500 dating back to January 4, 1950 and the code used to generate it. Does the data look normal? Yes/no}\spc{0}

\begin{figure}[h]
\centering
\includegraphics[width=7in]{daily_returns}
\end{figure}

%\begin{verbatim}
%X = read.csv('sp_tot_ret_price_1950.csv')
%n = nrow(X)
%n
%hist(X[,4], br = 1000, 
%  main = 'daily returns (as a percentage) of the S&P 500')
%\end{verbatim}

\intermediatesubproblem{Do you think the data is $\iid$? Explain.}\spc{1}

\intermediatesubproblem{Assume $\iid$ normal data regardless of what you wrote in (a) and (b). The sample average is $\xbar = 0.0003415$ and the sample standard deviation is $s = 0.0096$. Under an objective prior, give a 95\% credible region for the true mean daily return.}\spc{4}

\hardsubproblem{Give a 95\% predictive region for \emph{tomorrow's} return.}\spc{4}

\end{enumerate}

\end{document}


